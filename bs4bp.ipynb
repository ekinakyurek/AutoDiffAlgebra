{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "import Base: \\\n",
    "# function LinearAlgebra.Bidiagonal(dv::AbstractVector{T}, ev::AbstractVector{S}, uplo::Symbol) where {T,S}\n",
    "#     TS = promote_type(T,S)\n",
    "#     Bidiagonal(convert(AbstractVector{TS}, dv),\n",
    "#                convert(AbstractVector{TS}, ev),\n",
    "#                 uplo)\n",
    "# end\n",
    "\n",
    "\n",
    "# ## The base method narrows the type too much. We'll have to ensure that it's as least as wide as the input\n",
    "# function  \\(adjA::Adjoint{<:Any,<:Union{UnitUpperTriangular,UnitLowerTriangular}}, B::AbstractVector)\n",
    "#     A = adjA.parent\n",
    "#     TAB = promote_type(eltype(A), eltype(B), typeof(zero(eltype(A))*zero(eltype(B)) + zero(eltype(A))*zero(eltype(B))))\n",
    "#     BB = similar(B, TAB, size(B))\n",
    "#     copyto!(BB, B)\n",
    "#     ldiv!(adjoint(convert(AbstractArray{TAB}, A)), BB)\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h(x) = exp(-x)\n",
    "h‚Ä≤(x) = -exp(-x)\n",
    "h‚Ä≤(x,y) = -y\n",
    "ùìÅ(x,y) = sum(abs2,x-y)/2\n",
    "ùìÅ‚Ä≤(x,y) = x-y\n",
    "init(sizes...) = 0.01randn(sizes...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ùúÄ = 0.0001\n",
    "n = [5,4,3,1]\n",
    "N = length(n)-1\n",
    "B = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Params: [ $ \\ $[$w_i$, $b_i$] $ \\ $ for $i=1,...,N$] <br>\n",
    "Input: $x_1$ <br>\n",
    "Intermediate: $x_{i+1}=h(w_ix_i+b_i)$ for $i=1,...,N$ <br>\n",
    "Intermediate: $\\delta_i = h^{\\prime}(w_ix_i+b_i))$ for $i=1,...,N$<br>\n",
    "Output: X = [$x_1,\\ldots,x_{N+1}$]<br>\n",
    "Output: Œ¥ =  [$\\delta_1,\\ldots,\\delta_N$] <br>\n",
    "y: data (used in loss function ùìÅ(x,y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_net (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_net(params, input; h=h, h‚Ä≤=h‚Ä≤, N=length(params))\n",
    "    Œî = [];\n",
    "    X = [input];\n",
    "    for i=1:N\n",
    "        x = sum(params[i] .* [X[i],1])\n",
    "        push!(X,h(x))\n",
    "        push!(Œî, h‚Ä≤.(x,X[i+1]))\n",
    "    end\n",
    "    return X,Œî\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.015192320630271504, 0.029450987349552742)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params =[[init(),init()] for i=1:N] # W and B\n",
    "x,y = init(),init() # input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Vector{Float64}}:\n",
       " [9.485452549408101e-7, -6.243583702747712e-5]\n",
       " [-0.002884495624013203, -0.0028846090763231945]\n",
       " [-0.9825250277161762, -0.9610226017210001]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Œ¥ = neural_net(params,x)\n",
    "L   = Bidiagonal(zeros(N),[Œ¥[i] * params[i][1] for i=2:N],:L)\n",
    "D   = Diagonal(Œ¥.*[[X[i],1]' for i=1:N])\n",
    "g   = [zeros(N-1);ùìÅ‚Ä≤(X[N+1],y)]\n",
    "‚àáJ  = D'*((I-L')\\g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Vector{Float64}}:\n",
       " [9.485451313295812e-7, -6.243583733356317e-5]\n",
       " [-0.002884495629018602, -0.0028846090813217096]\n",
       " [-0.9825250347195169, -0.9610226082745754]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‚àáJfd is gradient calculated with finite differences method\n",
    "‚àáJfd = ‚àáJ * 0\n",
    "œµ    = ‚àáJ * 0\n",
    "for i=1:N, j=1:2       \n",
    "    œµ[i][j] = ùúÄ\n",
    "    ‚àáJfd[i][j]=(ùìÅ(neural_net(params.+œµ,x)[1][N+1],y)-ùìÅ(neural_net(params.-œµ,x)[1][N+1],y))/2ùúÄ\n",
    "    œµ[i][j] = .0\n",
    "end\n",
    "‚àáJfd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "* (generic function with 372 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: +,-,*,/,‚àò\n",
    "\n",
    "struct LinearMatrixOp # Is parametric type necessary? It causes un-readable error messages and some other issues.\n",
    "    f\n",
    "    fadj\n",
    "end\n",
    "LinearMatrixOp(f::Function) = LinearMatrixOp(f,f)\n",
    "\n",
    "LeftMul(A::AbstractMatrix) = LinearMatrixOp(X->A*X, X->A'*X)\n",
    "\n",
    "\n",
    "RightMul(A::Union{AbstractMatrix,AbstractVector}) = LinearMatrixOp(X->X*A, X->X*A')\n",
    "HadMul(A::Union{AbstractMatrix,AbstractVector}) = LinearMatrixOp(X->X.*A)\n",
    "ZeroMul() = LinearMatrixOp(X->Zero())\n",
    "IdentMul() = LinearMatrixOp(X->X) #not neccessary, can be commented\n",
    "\n",
    "Base.zero(::Type{LinearMatrixOp}) = ZeroMul() \n",
    "Base.one(::Type{LinearMatrixOp}) = IdentMul()\n",
    "Base.adjoint(A::LinearMatrixOp) = LinearMatrixOp(A.fadj,A.f)\n",
    "Base.copy(A::LinearMatrixOp) =  LinearMatrixOp(A.f,A.fadj)\n",
    "\n",
    "*(A::LinearMatrixOp,X::Union{AbstractArray,Number}) = A.f(X)\n",
    "-(A::LinearMatrixOp) = LinearMatrixOp(X->-A.f(X), X->-A.fadj(X))\n",
    "‚àò(A::LinearMatrixOp, B::LinearMatrixOp) = LinearMatrixOp(A.f ‚àò B.f, B.fadj ‚àò A.fadj)\n",
    "\n",
    "# A zero\n",
    "struct Zero end\n",
    "Base.zero(::Type{Any}) = Zero()\n",
    "+(::Zero, ::Zero) = Zero()\n",
    "-(::Zero, A) = -A\n",
    "+(::Zero, A) = A\n",
    "*(::Zero, ::Zero) = Zero()\n",
    "*(X, ::Zero) = Zero()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bernie wants a vector example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [5,4,3,1]\n",
    "N = length(n)-1\n",
    "params =[[.1randn(n[i+1],n[i]),.1randn(n[i+1])] for i=1:N]\n",
    "X‚ÇÅ, y = randn(n[1]), randn(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_net(params,input; h=h,h‚Ä≤= h‚Ä≤)\n",
    "    X     = [input]\n",
    "    Œî     = []\n",
    "    for i=1:length(params)\n",
    "        t = params[i][1]*X[i] .+ params[i][2]         \n",
    "        push!(X,h.(t))\n",
    "        push!(Œî,h‚Ä≤.(t))\n",
    "    end \n",
    "    X,Œî\n",
    "end\n",
    "array(x)= fill(x,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Matrix{Any}}:\n",
       " [[0.010343548314343382 -0.03349325028697286 ‚Ä¶ 0.014558585395377516 0.016513138118211413; 0.0033082815826314515 -0.010712484700555283 ‚Ä¶ 0.004656419486715778 0.005281563835514039; 0.022784517975740128 -0.07377812139875331 ‚Ä¶ 0.0320692996795253 0.036374741129069854; -0.0007857569142793368 0.0025443447639900123 ‚Ä¶ -0.0011059559823084024 -0.001254435330943584]; [-0.02744930330075746, -0.008779388059708145, -0.06046466120435512, 0.002085210916529661]]\n",
       " [[0.13484921906943864 0.11320772738803518 0.1626659890366508 0.08676544692535836; 0.013040128012007256 0.01094736230046856 0.01573005268310395 0.00839035288994206; -0.10686544468774763 -0.08971497360457091 -0.12890970651467146 -0.06875996860193152]; [0.12054682604831742, 0.011657064489945464, -0.09553106988863208]]\n",
       " [[-0.5929107928462909 -0.5084669931169483 -1.28955008112464]; [-0.6816245032662562]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Œî = neural_net(params,X‚ÇÅ)\n",
    "W = [params[i][1] for i=1:N]\n",
    "D = Diagonal([[HadMul(Œî[i]) ‚àò RightMul(X[i]) HadMul(Œî[i])] for i=1:N])\n",
    "I_minus_L = Bidiagonal([I for i in 1:N], -[HadMul(Œî[i]) ‚àò LeftMul(W[i]) for i=2:N] , :L)\n",
    "g = [ [Zero() for i=1:N-1]; [ùìÅ‚Ä≤(X[N+1],y)] ]\n",
    "‚àáJ = D'*array.(I_minus_L'\\g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Vector{Array{Float64,N} where N}}:\n",
       " [[0.010343548318969553 -0.0334932504383878 ‚Ä¶ 0.014558585407220548 0.016513138136331484; 0.00330828158312535 -0.010712484722619209 ‚Ä¶ 0.004656419488324737 0.005281563838221981; 0.022784517987040065 -0.07377812177272736 ‚Ä¶ 0.032069299709946986 0.036374741174127756; -0.0007857569145341969 0.0025443447712603096 ‚Ä¶ -0.0011059559831827492 -0.0012544353317212042], [-0.027449303383886292, -0.008779388071811223, -0.060464661410242204, 0.0020852109208768788]]\n",
       " [[0.13484921907502834 0.11320772739159546 0.16266598904662866 0.086765446926651; 0.013040128036267973 0.010947362314717157 0.015730052725648758 0.008390352896348041; -0.10686544512639173 -0.08971497386406346 -0.12890970728457463 -0.06875996871852363], [0.12054682605205924, 0.011657064507286652, -0.09553107020221496]]\n",
       " [[-0.5929107960633839 -0.5084669951460619 -1.2895501142246024], [-0.6816245081542327]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ‚àáJfd gradient finite differences\n",
    "‚àáJfd = params*0\n",
    "œµ=params*0\n",
    "for i=1:length(params), wb=1:2\n",
    "    for j=1:length(œµ[i][wb])\n",
    "        œµ[i][wb][j] = ùúÄ\n",
    "        ‚àáJfd[i][wb][j] =(ùìÅ(neural_net(params+œµ,X‚ÇÅ)[1][N+1],y)-ùìÅ(neural_net(params-œµ,X‚ÇÅ)[1][N+1],y))/2ùúÄ\n",
    "        œµ[i][wb][j] = .0\n",
    "     end\n",
    "end\n",
    "‚àáJfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Params: [ $ \\ $[$W_i$, $b_i$] $ \\ $ for $i=1,...,N$].<br>\n",
    "$W_i$ is $n_{i+1} \\times n_i$. <br>\n",
    "$b_i$ is $n_{i+1}$  <br> <br>\n",
    "Input: $X_1$ is $n_1 \\times B$. ($B$ = Batch size)  <br>\n",
    "(In the below the dot in matrix plus vector means broadcast to all columns) <br>\n",
    "Intermediate: $X_{i+1}=h(W_iX_i.+b_i)$ for $i=1,...,N$ <br>\n",
    "Intermediate: $\\delta_i = h^{\\prime}(W_ix_i.+b_i))$ for $i=1,...,N$<br>\n",
    "Output: X = [$X_1,\\ldots,X_{N+1}$] (Each $X_i$ is $n_i \\times B$) <br>\n",
    "Output: Œî =  [$\\Delta_1,\\ldots,\\Delta_N$]  (Each $\\Delta_i$ is $n_i \\times B$) <br>\n",
    "    y: 1xB (used in loss function ùìÅ($X_1$,y) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params: `W_i` and `b_i`s: x_{i+1} <- Wi * x_i .+ b_i\n",
    "\n",
    "n = [5,4,3,1] \n",
    "N = length(n)-1\n",
    "B = 1\n",
    "\n",
    "params =[[.1randn(n[i+1],n[i]),.1randn(n[i+1])] for i=1:N]\n",
    "X‚ÇÅ, y = randn(n[1],B), randn(1,B);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\begin{pmatrix}\n",
    "        dX_2 \\\\\n",
    "        dX_3 \\\\\n",
    "        \\vdots \\\\\n",
    "        dX_N \\\\\n",
    "        dX_{N+1}\n",
    "    \\end{pmatrix} = diag\n",
    "        \\begin{pmatrix}\n",
    "        [H(\\Delta_1)  \\circ R(X_1) \\,\\, H(\\Delta_1)] \\\\\n",
    "        [H(\\Delta_1)  \\circ R(X_2) \\,\\, H(\\Delta_2)] \\\\\n",
    "         \\vdots \\\\\n",
    "        [H(\\Delta_{N-1})  \\circ R(X_{N-1}) \\,\\, H(\\Delta_{N-1})] \\\\ \n",
    "         [H(\\Delta_{N})  \\circ R(X_{N}) \\,\\, H(\\Delta_{N})]\n",
    "    \\end{pmatrix}\n",
    "    \\begin{pmatrix}\n",
    "        [dW_1; dB_1]\\\\\n",
    "        [dW_2; dB_2]\\\\\n",
    "        \\vdots \\\\\n",
    "        [dW_{N-1};dB_{N-1}] \\\\ \n",
    "        [dW_N; dB_N]\n",
    "    \\end{pmatrix}\n",
    "    $ <br>\n",
    "    $\n",
    "    +  \\begin{pmatrix}\n",
    "        0 & \\ldots & 0 & 0 & 0 \\\\\n",
    "        H(\\Delta_2) \\circ L(W_2) & \\ldots & 0 & 0 & 0 \\\\\n",
    "        & \\ddots \\\\\n",
    "        && H(\\Delta_{N-1}) \\circ L(W_{N-1}) & 0 & 0\\\\\n",
    "        &&& H(\\Delta_{N}) \\circ L(W_{N})& 0 \\\\\n",
    "    \\end{pmatrix}\n",
    "     \\begin{pmatrix}\n",
    "        dX_2 \\\\\n",
    "        dX_3 \\\\\n",
    "        \\vdots \\\\\n",
    "        dX_N \\\\\n",
    "        dX_{N+1}\n",
    "    \\end{pmatrix}\n",
    "    $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Œî = neural_net(params,X‚ÇÅ)\n",
    "W = [params[i][1] for i=1:N]\n",
    "D = Diagonal([[HadMul(Œî[i]) ‚àò RightMul(X[i]) HadMul(Œî[i])] for i=1:N])\n",
    "I_minus_L = Bidiagonal([I for i in 1:N], -[HadMul(Œî[i]) ‚àò LeftMul(W[i]) for i=2:N] , :L)\n",
    "g = [ [Zero() for i=1:N-1]; [ùìÅ‚Ä≤(X[N+1],y)] ]\n",
    "‚àáJ = D'*array.(I_minus_L'\\g);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5√ó1 Matrix{Float64}:\n",
       " -0.7609461743103296\n",
       "  0.06376474224006651\n",
       "  0.24165987100463138\n",
       "  0.7322391447630908\n",
       " -0.07482665336968171"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚àáJfd gradient finite differences\n",
    "‚àáJfd = params*0\n",
    "œµ=params*0\n",
    "for i=1:length(params), wb=1:2\n",
    "    for j=1:length(œµ[i][wb])\n",
    "        œµ[i][wb][j] = ùúÄ\n",
    "        ‚àáJfd[i][wb][j] =(ùìÅ(neural_net(params+œµ,X‚ÇÅ)[1][N+1],y)-ùìÅ(neural_net(params-œµ,X‚ÇÅ)[1][N+1],y))/2ùúÄ\n",
    "        œµ[i][wb][j] = .0\n",
    "     end\n",
    "end\n",
    "‚àáJfd;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó5 Matrix{Float64}:\n",
       " -0.0110386     0.000924994   0.0035056     0.0106221    -0.00108546\n",
       " -0.0063253     0.000530039   0.00200878    0.00608667   -0.00062199\n",
       "  0.000103981  -8.71323e-6   -3.3022e-5    -0.000100058   1.02248e-5\n",
       " -0.00160644    0.000134614   0.000510169   0.00154583   -0.000157967"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "‚àáJ[1,1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó5 Matrix{Float64}:\n",
       " -0.0110386     0.000924994   0.0035056     0.0106221    -0.00108546\n",
       " -0.0063253     0.000530039   0.00200878    0.00608667   -0.00062199\n",
       "  0.000103981  -8.71323e-6   -3.3022e-5    -0.000100058   1.02248e-5\n",
       " -0.00160644    0.000134614   0.000510169   0.00154583   -0.000157967"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "‚àáJfd[1,1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = [5,4,3,1]\n",
    "N = length(n)-1\n",
    "ùúÄ = 0.0001\n",
    "B = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_net(params,input;h=h,h‚Ä≤=h‚Ä≤)\n",
    "    X     = [input]\n",
    "    Œ¥     = []\n",
    "    for i=1:length(params)\n",
    "        x = params[i][1]*X[i] .+ params[i][2]         \n",
    "        push!(X,h.(x))\n",
    "        push!(Œ¥,h‚Ä≤.(x,X[i+1]))\n",
    "    end \n",
    "    X,Œ¥\n",
    "end\n",
    "array(x)= fill(x,1,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "params: `W_i` and `b_i`s: x_{i+1} <- Wi*x_i .+ b_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "params =[[init(n[i+1],n[i]),init(n[i+1])] for i=1:N]\n",
    "x, y = init(n[1],B), init(1,B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Matrix{Any}}:\n",
       " [[1.2500176587353581e-5 6.590525686816944e-6 ‚Ä¶ -6.113225135061867e-6 -7.801383448250018e-6; -1.497817760603035e-6 -7.893995308292463e-7 ‚Ä¶ 7.326570720015704e-7 9.347948871601612e-7; -1.3118352365875809e-5 -6.919726649867388e-6 ‚Ä¶ 6.4180757058971916e-6 8.184254421786065e-6; 2.6964481150250814e-6 1.4220392094734789e-6 ‚Ä¶ -1.3193220048995069e-6 -1.6840438370848367e-6]; [0.0002816118885992652 0.0002831657750439727 ‚Ä¶ 0.00028085789964974454 0.000278715943704693; -3.3732806094589646e-5 -3.3910179095024034e-5 ‚Ä¶ -3.36451232528617e-5 -3.338860585847111e-5; -0.00029553494209633786 -0.00029715254303487533 ‚Ä¶ -0.00029461189284070324 -0.00029248365031532477; 6.076446415123484e-5 6.109104356353871e-5 ‚Ä¶ 6.056784978155905e-5 6.0138290040488675e-5]]\n",
       " [[-0.11914481927960491 -0.11939400217154643 -0.12142031083673799 -0.11862043357437975; -0.04098923255791988 -0.04107495861086029 -0.04177206685944679 -0.04080882881724512; 0.012261922481493994 0.012287567409821697 0.012496107239999915 0.012207954735078255]; [-0.017236030838188744 -0.0173295325306644 ‚Ä¶ -0.01718708674143989 -0.01705712222651407; -0.005929671964997313 -0.005961846489688294 ‚Ä¶ -0.0059128820442075035 -0.005868122394661552; 0.00177386553119284 0.0017834947434719863 ‚Ä¶ 0.0017688327163723366 0.001755453363987417]]\n",
       " [[-7.627749394854904 -7.489509902271744 -7.630502225931881]; [-1.0799725443231545 -1.0858319291730896 ‚Ä¶ -1.076912931470594 -1.068762969060929]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Œ¥ = neural_net(params,x)\n",
    "D = Diagonal([[HadMul(Œ¥[i]) ‚àò RightMul(X[i]) HadMul(Œ¥[i])] for i=1:N])\n",
    "ImL = Bidiagonal([I for i in 1:N], -[HadMul(Œ¥[i]) ‚àò LeftMul(params[i][1]) for i=2:N] , :L)\n",
    "g = [ [Zero() for i=1:N-1]; [ùìÅ‚Ä≤(X[N+1],y)] ] \n",
    "‚àáJ = D'*array.(ImL'\\g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚àáJfd is gradient calculated with finite differences method\n",
    "‚àáJfd = params*0\n",
    "œµ=params*0\n",
    "for i=1:length(params), wb=1:2\n",
    "    for j=1:length(œµ[i][wb])\n",
    "        œµ[i][wb][j] = ùúÄ\n",
    "        ‚àáJfd[i][wb][j] =(ùìÅ(neural_net(params+œµ,x)[1][N+1],y)-ùìÅ(neural_net(params-œµ,x)[1][N+1],y))/2ùúÄ\n",
    "        œµ[i][wb][j] = .0\n",
    "     end\n",
    "end\n",
    "‚àáJfd;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó5 Matrix{Float64}:\n",
       "  1.25002e-5   6.59053e-6   7.57094e-7  -6.11322e-6  -7.80139e-6\n",
       " -1.49782e-6  -7.89402e-7  -9.05409e-8   7.32658e-7   9.34797e-7\n",
       " -1.31184e-5  -6.91972e-6  -7.98037e-7   6.41807e-6   8.18425e-6\n",
       "  2.69645e-6   1.42204e-6   1.63012e-7  -1.31932e-6  -1.68404e-6"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "‚àáJfd[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó5 Matrix{Float64}:\n",
       "  1.25002e-5   6.59053e-6   7.57093e-7  -6.11323e-6  -7.80138e-6\n",
       " -1.49782e-6  -7.894e-7    -9.05418e-8   7.32657e-7   9.34795e-7\n",
       " -1.31184e-5  -6.91973e-6  -7.98037e-7   6.41808e-6   8.18425e-6\n",
       "  2.69645e-6   1.42204e-6   1.63011e-7  -1.31932e-6  -1.68404e-6"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "‚àáJ[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Showcase: Densely Connected Matrix Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "function neural_net(params,input;h=h, h‚Ä≤= h‚Ä≤)\n",
    "    X     = [input]\n",
    "    Œ¥     = []\n",
    "    for i in 1:length(params)\n",
    "       x = broadcast(+,(params[i] .* [X..., I])...)\n",
    "       push!(X,h.(x))\n",
    "       push!(Œ¥,h‚Ä≤.(x,X[i+1]))\n",
    "    end \n",
    "    X,Œ¥\n",
    "end;\n",
    "array(x) = fill(x,1,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [[j==i+1 ?  init(n[i+1],1) : init(n[i+1],n[j])  for j=1:i+1] for i=1:N]\n",
    "x,y = init(n[1],B), init(1,B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Matrix{Any}}:\n",
       " [[8.108631009110678e-6 8.080304654661267e-6 ‚Ä¶ -1.1903004166362233e-5 -4.509977123148807e-6; 0.0001569435563928751 0.0001563036807495304 ‚Ä¶ -0.00023036396471757455 -8.727210947246424e-5; -4.385086358119289e-5 -4.3667337959258324e-5 ‚Ä¶ 6.434376408235784e-5 2.4376731382031054e-5; -0.00031353109166912176 -0.00031228829982786574 ‚Ä¶ 0.000460202724885639 0.00017439672331565542]; [0.00037949609136086673 0.0003885390442528399 ‚Ä¶ 0.0003809831692149818 0.00038318582221509085; 0.007343805643799245 0.007518728923223524 ‚Ä¶ 0.007375438607441067 0.007416708692183254; -0.0020518412290114843 -0.002100025709284073 ‚Ä¶ -0.002059618845014968 -0.002072053456902055; -0.01467356577043743 -0.015019076984295136 ‚Ä¶ -0.014734312002491796 -0.014818622930994889]]\n",
       " [[2.3220833299198935e-5 2.3113300575941924e-5 ‚Ä¶ -3.4068091493727626e-5 -1.2903865722413128e-5; -5.520694331066404e-5 -5.496383785617488e-5 ‚Ä¶ 8.099538606053649e-5 3.067865094392669e-5; 0.00014739321149422594 0.00014686552504624686 ‚Ä¶ -0.00021637524499226653 -8.202134312663566e-5]; [0.007712049263869787 0.007643166944687188 0.007638345414892975 0.007701760227025048; -0.01833504141288391 -0.018171276576826136 -0.018159813660556898 -0.01831057945999077; 0.0489903783808017 0.04855280453325827 0.04852217428485928 0.04892501639871082]; [0.0010861188336981796 0.0011118183674002917 ‚Ä¶ 0.0010904564427537255 0.0010972184051595093; -0.0025825110876516767 -0.002643505255274289 ‚Ä¶ -0.002592249051044046 -0.0026084237025698004; 0.006899946932347111 0.007061371658291979 ‚Ä¶ 0.006927423611238456 0.0069672733734658715]]\n",
       " [[-0.02157271540163393 -0.021486052580435542 ‚Ä¶ 0.03166062542832017 0.011995777827865216]; [-7.167714191519808 -7.1036935037205255 -7.099212114734782 -7.158151207478469]; [-7.1669958455047675 -7.018077219690513 -7.0354143840853425]; [-1.0094989605265685 -1.0333568499591597 ‚Ä¶ -1.0135521029087033 -1.0194674777914288]]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,Œ¥ = neural_net(params,x)\n",
    "D = Diagonal([[[(HadMul(Œ¥[i]) ‚àò RightMul(X[j]))' for j=1:i]' HadMul(Œ¥[i])] for i=1:N])\n",
    "ImL = UnitLowerTriangular(Matrix{Any}(undef,N,N))\n",
    "for i=2:N, j=1:i-1\n",
    "    ImL[i,j] = -HadMul(Œ¥[i]) ‚àò LeftMul(params[i][j+1]) \n",
    "end\n",
    "g =[ [Zero() for i=1:N-1]; [ùìÅ‚Ä≤(X[N+1],y)] ] \n",
    "‚àáJ = D'*array.(ImL'\\g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚àáJfd is gradient calculated with finite differences method\n",
    "‚àáJfd = params*0\n",
    "œµ=params*0\n",
    "for i=1:length(œµ), j=1:length(œµ[i]), k=1:length(œµ[i][j])\n",
    "        œµ[i][j][k] = ùúÄ\n",
    "        ‚àáJfd[i][j][k] =(ùìÅ(neural_net(params+œµ,x)[1][N+1],y)-ùìÅ(neural_net(params-œµ,x)[1][N+1],y))/2ùúÄ\n",
    "        œµ[i][j][k] = .0\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4√ó5 Matrix{Float64}:\n",
       "  8.10863e-6    8.08031e-6   -2.16377e-6  -1.1903e-5    -4.50998e-6\n",
       "  0.000156944   0.000156304  -4.19521e-5  -0.000230364  -8.72721e-5\n",
       " -4.38509e-5   -4.36673e-5    1.17407e-5   6.43438e-5    2.43767e-5\n",
       " -0.000313531  -0.000312288   8.37816e-5   0.000460203   0.000174397"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "‚àáJfd[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "‚àáJ[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with Orthogonal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [2,2,2,1]\n",
    "N = length(n)-1\n",
    "B = 7\n",
    "h(x) = exp(-x)\n",
    "h‚Ä≤(x,y) = -y\n",
    "ùìÅ(x,y) = sum(abs2,x-y)/2\n",
    "ùìÅ‚Ä≤(x,y) = x-y\n",
    "init(sizes...) = 0.01randn(sizes...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct OrthogonalTransform{T} <: AbstractMatrix{T}\n",
    "    Œ∏::T\n",
    "end\n",
    "Base.Matrix{T}(R::OrthogonalTransform{T}) where T =   [cos(R.Œ∏) -sin(R.Œ∏); sin(R.Œ∏) cos(R.Œ∏)] \n",
    "*(R::OrthogonalTransform, x::AbstractArray{T,2} where T) = [cos(R.Œ∏) -sin(R.Œ∏); sin(R.Œ∏) cos(R.Œ∏)]  * x\n",
    "Base.adjoint(R::OrthogonalTransform) = OrthogonalTransform(-R.Œ∏)\n",
    "Base.size(R::OrthogonalTransform) = (2,2)\n",
    "Base.getindex(R::OrthogonalTransform, inds...) = [cos(R.Œ∏) -sin(R.Œ∏); sin(R.Œ∏) cos(R.Œ∏)][inds...]\n",
    "-(R::OrthogonalTransform{T}) where T = OrthogonalTransform{T}(-R.Œ∏)\n",
    "Ort(Q::OrthogonalTransform) = LinearMatrixOp(X->Q*X, X->(X-Q*X'*Q)/2) # onl definition needed so far. So I left f as identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function neural_net(params,input;h=h,h‚Ä≤= h‚Ä≤)\n",
    "    X     = [input]\n",
    "    Œ¥     = []\n",
    "    for i=1:length(params)\n",
    "        x = params[i][1]*X[i] .+ params[i][2]         \n",
    "        push!(X,h.(x))\n",
    "        push!(Œ¥,h‚Ä≤.(x,X[i+1]))\n",
    "    end \n",
    "    X,Œ¥\n",
    "end\n",
    "array(x)= fill(x,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OrthogonalTransform(œÄ/rand([1,2,3,4,6])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params: `W_i` and `b_i`s: x_{i+1} <- Wi*x_i .+ b_i\n",
    "params =[[(i!=N ? OrthogonalTransform(œÄ/rand([1,2,3,4,6])) : init(n[i+1],n[i])), init(n[i+1])] for i=1:N]\n",
    "x, y = init(n[1],B), init(1,B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Œ¥ = neural_net(params,x)\n",
    "D = Diagonal([[HadMul(Œ¥[i]) ‚àò RightMul(X[i]) ‚àò  (i!=N ? Ort(params[i][1]) : IdentMul())     HadMul(Œ¥[i])] for i=1:N])\n",
    "ImL = Bidiagonal([I for i in 1:N], -[HadMul(Œ¥[i]) ‚àò LeftMul(params[i][1]) for i=2:N] , :L)\n",
    "g = push!(Any[Zero() for i=1:N-1],ùìÅ‚Ä≤(X[N+1],y))\n",
    "‚àáJ = D'*array.(ImL'\\g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "diff = Matrix(OrthogonalTransform(params[1][1].Œ∏ + ùúÄ)) - Matrix(params[1][1])\n",
    "@show Œî = sum(diff.* ‚àáJ[1][1])\n",
    "orig    = ùìÅ(neural_net(params,x)[1][N+1],y)\n",
    "params[1][1] = OrthogonalTransform(params[1][1].Œ∏ + ùúÄ)\n",
    "updated = ùìÅ(neural_net(params,x)[1][N+1],y)\n",
    "params[1][1] = OrthogonalTransform(params[1][1].Œ∏ - ùúÄ)\n",
    "@show Œî = updated-orig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "struct HouseHolderTransform{T} <: AbstractMatrix{T}\n",
    "    mat::Matrix{T}\n",
    "end\n",
    "HouseHolderTransform(v::Vector{T}) where T = HouseHolderTransform(I-2*v*v')\n",
    "Base.Matrix{T}(R::HouseHolderTransform{T}) where T =   R.mat\n",
    "*(R::HouseHolderTransform, x::AbstractArray{T,2} where T) =  R.mat* x\n",
    "Base.adjoint(R::HouseHolderTransform) = HouseHolderTransform(permutedims(R.mat))\n",
    "Base.size(R::HouseHolderTransform) = size(R.mat)\n",
    "Base.getindex(R::HouseHolderTransform, inds...) = R.mat[inds...]\n",
    "-(R::HouseHolderTransform) = -R.mat\n",
    "Ort(Q::AbstractMatrix) = LinearMatrixOp(X->Q*X, X->(X-Q*X'*Q)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = [4,4,4,1]\n",
    "N = length(n)-1\n",
    "B = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params: `W_i` and `b_i`s: x_{i+1} <- Wi*x_i .+ b_i\n",
    "vs = [init(n[i]) for i=1:N-1] # householder parameters\n",
    "vs = map(v-> (v ./ norm(v)), vs)\n",
    "params =[[(i!=N ? HouseHolderTransform(vs[i]) : init(n[i+1],n[i])), init(n[i+1])] for i=1:N]\n",
    "x, y = init(n[1],B), init(1,B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Œ¥ = neural_net(params,x)\n",
    "D = Diagonal([[HadMul(Œ¥[i]) ‚àò RightMul(X[i]) ‚àò  (i!=N ? Ort(params[i][1]) : IdentMul())     HadMul(Œ¥[i])] for i=1:N])\n",
    "ImL = Bidiagonal([I for i in 1:N], -[HadMul(Œ¥[i]) ‚àò LeftMul(params[i][1]) for i=2:N] , :L)\n",
    "g = push!(Any[Zero() for i=1:N-1],ùìÅ‚Ä≤(X[N+1],y))\n",
    "‚àáJ = D'*array.(ImL'\\g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "‚àáJ[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test\n",
    "vs1_changed = vs[1] .+ ùúÄ\n",
    "vs1_changed = vs1_changed ./ norm(vs1_changed)\n",
    "#vs1_changed[1] = vs[1][1] + ùúÄ\n",
    "diff = Matrix(HouseHolderTransform(vs1_changed)) - Matrix(params[1][1])\n",
    "@show Œî = sum(diff.* ‚àáJ[1][1])\n",
    "orig    = ùìÅ(neural_net(params,x)[1][N+1],y)\n",
    "params[1][1] = HouseHolderTransform(vs1_changed)\n",
    "updated = ùìÅ(neural_net(params,x)[1][N+1],y)\n",
    "params[1][1] = HouseHolderTransform(vs[1])\n",
    "@show Œî = updated-orig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs1_changed "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST MLP Example (didn't test on final version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "using Knet\n",
    "import Knet: Data\n",
    "include(Knet.dir(\"data\",\"mnist.jl\"))\n",
    "dtrn,dtst = mnistdata(xsize=(784,:)); # dtrn and dtst = [ (x1,y1), (x2,y2), ... ] where xi,yi are\n",
    "\n",
    "#Layers\n",
    "n = [784,128,64,10]\n",
    "N = length(n)-1\n",
    "init(sizes...) = 0.1randn(sizes...)\n",
    "\n",
    "#Nonlinearity\n",
    "h(x)    = x>0 ? x : zero(x) # relu\n",
    "h‚Ä≤(x,y) = y>0 ? one(x) : zero(x) # derivative of relu\n",
    "\n",
    "#Loss\n",
    "ùìÅ(x,a) = nll(x,a;average=true) # negative log likelihood loss, x is dxb matrix, \n",
    "                               # a is d-length integer array keeps the correct answers \n",
    "function ùìÅ‚Ä≤(x,a)  # Note!: this will be simplified if we can figure out how to integrate derivative of getindex in to our formulatin\n",
    "    indices = Knet.findindices(x,a,dims=1)\n",
    "    yz = zero(x)\n",
    "    yz[indices] .= 1\n",
    "    return (softmax(x,dims=1) .- yz)./length(a)\n",
    "end\n",
    "\n",
    "#Forward Function\n",
    "function neural_net(params,input;h=h,h‚Ä≤= h‚Ä≤)\n",
    "    X     = [input]; Œ¥     = []\n",
    "    for i=1:length(params)-1\n",
    "        x = params[i][1]*X[end] .+ params[i][2]         \n",
    "        push!(X,h.(x)); push!(Œ¥,h‚Ä≤.(x,X[end]))\n",
    "    end \n",
    "    x = params[end][1]*X[end] .+ params[end][2]    \n",
    "    push!(X,x); push!(Œ¥,one.(x))\n",
    "    X,Œ¥\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params =[[init(n[i+1],n[i]),zeros(n[i+1])] for i=1:N] # model parameters\n",
    "Œ± = 0.5 # learning rate \n",
    "epochs=3# number of epochs to train model \n",
    "@time for i=1:epochs # 1 epoch takes ~ 65 seconds  in my macbook\n",
    "    for (x,y) in dtrn\n",
    "        X,Œ¥ = neural_net(params,x;h=h, h‚Ä≤= h‚Ä≤)\n",
    "        D = Diagonal([[HadMul(Œ¥[i]) ‚àò RightMul(X[i]) HadMul(Œ¥[i])] for i=1:N])\n",
    "        ImL = Bidiagonal([I for i in 1:N], -[HadMul(Œ¥[i]) ‚àò LeftMul(params[i][1]) for i=2:N] , :L)\n",
    "        g = push!(Any[Zero() for i=1:N-1],ùìÅ‚Ä≤(X[N+1],y))\n",
    "        ‚àáJ = D'*array.(ImL'\\g);\n",
    "        for i =1:length(params)\n",
    "            params[i][1] = params[i][1] - Œ±*‚àáJ[i][1]\n",
    "            params[i][2] = params[i][2] - Œ±*sum(‚àáJ[i][2],dims=2)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroone=total=0\n",
    "for (x,y) in dtst\n",
    "    yn        = neural_net(params,x;h=h, h‚Ä≤= h‚Ä≤)[1][end]\n",
    "    answers   = vec(getindex.(argmax(yn,dims=1),1))\n",
    "    global zeroone += sum(y .== answers)\n",
    "    global total   += length(answers)\n",
    "end\n",
    "accuracy = 100zeroone/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.6.0-DEV",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
