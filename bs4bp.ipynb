{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\\ (generic function with 152 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using LinearAlgebra\n",
    "import Base: \\\n",
    "function LinearAlgebra.Bidiagonal(dv::Vector{T}, ev::Vector{S}, uplo::Symbol) where {T,S}\n",
    "    TS = promote_type(T,S)\n",
    "    return Bidiagonal{TS,Vector{TS}}(dv, ev, uplo)\n",
    "end\n",
    "\n",
    "\n",
    "## The base method narrows the type too much. We'll have to ensure that it's as least as wide as the input\n",
    "function  \\(adjA::Adjoint{<:Any,<:Union{UnitUpperTriangular,UnitLowerTriangular}}, B::AbstractVector)\n",
    "    A = adjA.parent\n",
    "    TAB = promote_type(eltype(A), eltype(B), typeof(zero(eltype(A))*zero(eltype(B)) + zero(eltype(A))*zero(eltype(B))))\n",
    "    BB = similar(B, TAB, size(B))\n",
    "    copyto!(BB, B)\n",
    "    ldiv!(adjoint(convert(AbstractArray{TAB}, A)), BB)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h(x) = exp(-x)\n",
    "h′(x,y) = -y\n",
    "𝓁(x,y) = sum(abs2,x-y)/2\n",
    "𝓁′(x,y) = x-y\n",
    "init(sizes...) = 0.01randn(sizes...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "𝜀 = .0001\n",
    "n = [5,4,3,1]\n",
    "N = length(n)-1\n",
    "B = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neural_net (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_net(params, input; h=h, h′=h′, N=length(params))\n",
    "    δ = [];\n",
    "    X = [input];\n",
    "    for i=1:N\n",
    "        x = sum(params[i] .* [X[i],1])\n",
    "        push!(X,h(x))\n",
    "        push!(δ, h′.(x,X[i+1]))\n",
    "    end\n",
    "    return X,δ\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0168052294474895, 0.00869503242558762)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params =[[init(),init()] for i=1:N] # W and B\n",
    "x,y = init(),init() # input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Float64,1},1}:\n",
       " [-1.85356e-6, -0.000110297]\n",
       " [-0.00603026, -0.0059671]  \n",
       " [-1.04597, -1.02742]       "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,δ = neural_net(params,x)\n",
    "L   = Bidiagonal(zeros(N),[δ[i] * params[i][1] for i=2:N],:L)\n",
    "D   = Diagonal(δ.*[[X[i],1]' for i=1:N])\n",
    "g   = [zeros(N-1);𝓁′(X[N+1],y)]\n",
    "∇J  = D'*((I-L')\\g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Float64,1},1}:\n",
       " [-1.85356e-6, -0.000110297]\n",
       " [-0.00603026, -0.0059671]  \n",
       " [-1.04597, -1.02742]       "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ∇Jfd is gradient calculated with finite differences method\n",
    "∇Jfd = ∇J * 0\n",
    "ϵ    = ∇J * 0\n",
    "for i=1:N, j=1:2       \n",
    "    ϵ[i][j] = 𝜀\n",
    "    ∇Jfd[i][j]=(𝓁(neural_net(params.+ϵ,x)[1][N+1],y)-𝓁(neural_net(params.-ϵ,x)[1][N+1],y))/2𝜀\n",
    "    ϵ[i][j] = .0\n",
    "end\n",
    "∇Jfd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "* (generic function with 349 methods)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import Base: +,-,*,/,∘\n",
    "\n",
    "struct LinearMatrixOp # Is parametric type necessary? It causes un-readable error messages and some other issues.\n",
    "    f\n",
    "    fadj\n",
    "end\n",
    "LinearMatrixOp(f::Function) = LinearMatrixOp(f,f)\n",
    "\n",
    "LeftMul(A::AbstractMatrix) = LinearMatrixOp(X->A*X, X->A'*X)\n",
    "\n",
    "\n",
    "RightMul(A::AbstractMatrix) = LinearMatrixOp(X->X*A, X->X*A')\n",
    "HadMul(A::AbstractMatrix) = LinearMatrixOp(X->X.*A)\n",
    "ZeroMul() = LinearMatrixOp(X->Zero())\n",
    "IdentMul() = LinearMatrixOp(X->X) #not neccessary, can be commented\n",
    "\n",
    "Base.zero(::Type{LinearMatrixOp}) = ZeroMul() \n",
    "Base.one(::Type{LinearMatrixOp}) = IdentMul()\n",
    "Base.adjoint(A::LinearMatrixOp) = LinearMatrixOp(A.fadj,A.f)\n",
    "Base.copy(A::LinearMatrixOp) =  LinearMatrixOp(A.f,A.fadj)\n",
    "\n",
    "*(A::LinearMatrixOp,X::Union{AbstractArray,Number}) = A.f(X)\n",
    "-(A::LinearMatrixOp) = LinearMatrixOp(X->-A.f(X), X->-A.fadj(X))\n",
    "∘(A::LinearMatrixOp, B::LinearMatrixOp) = LinearMatrixOp(A.f ∘ B.f, B.fadj ∘ A.fadj)\n",
    "\n",
    "# A zero\n",
    "struct Zero end\n",
    "Base.zero(::Type{Any}) = Zero()\n",
    "+(::Zero, ::Zero) = Zero()\n",
    "-(::Zero, A) = -A\n",
    "+(::Zero, A) = A\n",
    "*(::Zero, ::Zero) = Zero()\n",
    "*(X, ::Zero) = Zero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_net(params,input;h=h,h′= h′)\n",
    "    X     = [input]\n",
    "    δ     = []\n",
    "    for i=1:length(params)\n",
    "        x = params[i][1]*X[i] .+ params[i][2]         \n",
    "        push!(X,h.(x))\n",
    "        push!(δ,h′.(x,X[i+1]))\n",
    "    end \n",
    "    X,δ\n",
    "end\n",
    "array(x)= fill(x,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params: `W_i` and `b_i`s: x_{i+1} <- Wi*x_i .+ b_i\n",
    "params =[[init(n[i+1],n[i]),init(n[i+1])] for i=1:N]\n",
    "x, y = init(n[1],B), init(1,B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Any,2},1}:\n",
       " [[-1.59067e-7 -2.09214e-7 … 4.62421e-8 -3.61611e-8; -6.0108e-7 -7.90725e-7 … 1.74694e-7 -1.36698e-7; 1.24805e-6 1.64242e-6 … -3.6276e-7 2.84086e-7; -1.56557e-7 -2.06013e-7 … 4.55584e-8 -3.55725e-8]; [5.61827e-6 5.65542e-6 … 5.59032e-6 5.65695e-6; 2.12416e-5 2.13802e-5 … 2.11266e-5 2.13824e-5; -4.41431e-5 -4.44135e-5 … -4.3878e-5 -4.44167e-5; 5.53313e-6 5.56989e-6 … 5.50453e-6 5.57091e-6]]\n",
       " [[0.00810725 0.00812535 0.00810091 0.008148; -0.0163362 -0.0163727 -0.0163235 -0.0164184; -0.00707229 -0.00708808 -0.00706676 -0.00710784]; [0.00115084 0.00115825 … 0.00114448 0.00115812; -0.00231897 -0.0023339 … -0.00230613 -0.00233362; -0.00100392 -0.00101038 … -0.000998366 -0.00101028]]                                                                                                     \n",
       " [[-7.12786 -7.13722 -7.77584]; [-1.04516 -1.05189 … -1.03938 -1.05178]]                                                                                                                                                                                                                                                                                                                                "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,δ = neural_net(params,x)\n",
    "D = Diagonal([[HadMul(δ[i]) ∘ RightMul(X[i]) HadMul(δ[i])] for i=1:N])\n",
    "ImL = Bidiagonal([I for i in 1:N], -[HadMul(δ[i]) ∘ LeftMul(params[i][1]) for i=2:N] , :L)\n",
    "g = [ [Zero() for i=1:N-1]; [𝓁′(X[N+1],y)] ] \n",
    "∇J = D'*array.(ImL'\\g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ∇Jfd is gradient calculated with finite differences method\n",
    "∇Jfd = params*0\n",
    "ϵ=params*0\n",
    "for i=1:length(params), wb=1:2\n",
    "    for j=1:length(ϵ[i][wb])\n",
    "        ϵ[i][wb][j] = 𝜀\n",
    "        ∇Jfd[i][wb][j] =(𝓁(neural_net(params+ϵ,x)[1][N+1],y)-𝓁(neural_net(params-ϵ,x)[1][N+1],y))/2𝜀\n",
    "        ϵ[i][wb][j] = .0\n",
    "     end\n",
    "end\n",
    "∇Jfd;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×5 Array{Float64,2}:\n",
       " -1.59068e-7  -2.09217e-7   6.68221e-8   4.62386e-8  -3.616e-8  \n",
       " -6.01079e-7  -7.90725e-7   2.52556e-7   1.74696e-7  -1.36697e-7\n",
       "  1.24805e-6   1.64242e-6  -5.24329e-7  -3.62761e-7   2.84084e-7\n",
       " -1.56553e-7  -2.06015e-7   6.57674e-8   4.55613e-8  -3.55715e-8"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×5 Array{Float64,2}:\n",
       " -1.59067e-7  -2.09214e-7   6.68235e-8   4.62421e-8  -3.61611e-8\n",
       " -6.0108e-7   -7.90725e-7   2.52558e-7   1.74694e-7  -1.36698e-7\n",
       "  1.24805e-6   1.64242e-6  -5.2433e-7   -3.6276e-7    2.84086e-7\n",
       " -1.56557e-7  -2.06013e-7   6.57683e-8   4.55584e-8  -3.55725e-8"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇J[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Showcase: Densely Connected Matrix Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "function neural_net(params,input;h=h, h′= h′)\n",
    "    X     = [input]\n",
    "    δ     = []\n",
    "    for i in 1:length(params)\n",
    "       x = broadcast(+,(params[i] .* [X..., I])...)\n",
    "       push!(X,h.(x))\n",
    "       push!(δ,h′.(x,X[i+1]))\n",
    "    end \n",
    "    X,δ\n",
    "end;\n",
    "array(x) = fill(x,1,1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [[j==i+1 ?  init(n[i+1],1) : init(n[i+1],n[j])  for j=1:i+1] for i=1:N]\n",
    "x,y = init(n[1],B), init(1,B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Any,2},1}:\n",
       " [[4.86838e-6 -0.00021486 … 6.18163e-5 -0.000185313; -1.37943e-6 6.11353e-5 … -1.75969e-5 5.27272e-5; -4.40213e-6 0.000195394 … -5.61808e-5 0.000168519; -5.65885e-6 0.000250325 … -7.20352e-5 0.000215918]; [0.00664594 0.00671516 … 0.00678023 0.00678137; -0.00189094 -0.00191047 … -0.00192941 -0.00192953; -0.00604304 -0.00610233 … -0.00616307 -0.00616435; -0.00774329 -0.00781828 … -0.00789594 -0.00790021]]                            \n",
       " [[-8.56756e-6 0.000377095 … -0.000108513 0.00032528; 3.48308e-6 -0.000154476 … 4.44189e-5 -0.000133239; -1.22994e-6 5.40883e-5 … -1.55688e-5 4.66486e-5]; [-0.0843554 -0.0828968 -0.0837584 -0.0824644; 0.0345309 0.0339338 0.0342865 0.0337568; -0.0120975 -0.0118883 -0.0120119 -0.0118263]; [-0.0116644 -0.0117983 … -0.0119111 -0.0119092; 0.00477761 0.00482704 … 0.00487509 0.00487497; -0.00167314 -0.00169188 … -0.00170797 -0.00170759]]\n",
       " [[-0.00075029 0.0331917 … -0.00955322 0.0286274]; [-7.42108 -7.29276 -7.36856 -7.25472]; [-7.33783 -7.41286 -7.36576]; [-1.02665 -1.03748 … -1.04766 -1.0477]]                                                                                                                                                                                                                                                                                   "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,δ = neural_net(params,x)\n",
    "D = Diagonal([[[(HadMul(δ[i]) ∘ RightMul(X[j]))' for j=1:i]' HadMul(δ[i])] for i=1:N])\n",
    "ImL = UnitLowerTriangular(Matrix{Any}(undef,N,N))\n",
    "for i=2:N, j=1:i-1\n",
    "    ImL[i,j] = -HadMul(δ[i]) ∘ LeftMul(params[i][j+1]) \n",
    "end\n",
    "g =[ [Zero() for i=1:N-1]; [𝓁′(X[N+1],y)] ] \n",
    "∇J = D'*array.(ImL'\\g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ∇Jfd is gradient calculated with finite differences method\n",
    "∇Jfd = params*0\n",
    "ϵ=params*0\n",
    "for i=1:length(ϵ), j=1:length(ϵ[i]), k=1:length(ϵ[i][j])\n",
    "        ϵ[i][j][k] = 𝜀\n",
    "        ∇Jfd[i][j][k] =(𝓁(neural_net(params+ϵ,x)[1][N+1],y)-𝓁(neural_net(params-ϵ,x)[1][N+1],y))/2𝜀\n",
    "        ϵ[i][j][k] = .0\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×5 Array{Float64,2}:\n",
       "  4.86838e-6  -0.00021486   -0.000272776   6.18163e-5  -0.000185313\n",
       " -1.37943e-6   6.11353e-5    7.76077e-5   -1.75969e-5   5.27272e-5 \n",
       " -4.40213e-6   0.000195394   0.000247964  -5.61808e-5   0.000168519\n",
       " -5.65885e-6   0.000250325   0.000317611  -7.20352e-5   0.000215918"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇Jfd[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×5 Array{Float64,2}:\n",
       "  4.86838e-6  -0.00021486   -0.000272776   6.18163e-5  -0.000185313\n",
       " -1.37943e-6   6.11353e-5    7.76077e-5   -1.75969e-5   5.27272e-5 \n",
       " -4.40213e-6   0.000195394   0.000247964  -5.61808e-5   0.000168519\n",
       " -5.65885e-6   0.000250325   0.000317611  -7.20352e-5   0.000215918"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇J[1][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST MLP Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/ekin/.julia/compiled/v1.1/Knet/f4vSz.ji for Knet [1902f260-5fb4-5aff-8c31-6271790ab950]\n",
      "└ @ Base loading.jl:1184\n",
      "ERROR: LoadError: InitError: /Users/ekin/.julia/packages/SpecialFunctions/fvheQ/deps/usr/lib/libopenspecfun.1.3.dylib cannot be opened, Please re-run Pkg.build(\"SpecialFunctions\"), and restart Julia.\n",
      "Stacktrace:\n",
      " [1] error(::String) at ./error.jl:33\n",
      " [2] check_deps() at /Users/ekin/.julia/packages/SpecialFunctions/fvheQ/deps/deps.jl:20\n",
      " [3] __init__() at /Users/ekin/.julia/packages/SpecialFunctions/fvheQ/src/SpecialFunctions.jl:12\n",
      " [4] _include_from_serialized(::String, ::Array{Any,1}) at ./loading.jl:633\n",
      " [5] _require_from_serialized(::String) at ./loading.jl:684\n",
      " [6] _require(::Base.PkgId) at ./loading.jl:967\n",
      " [7] require(::Base.PkgId) at ./loading.jl:858\n",
      " [8] require(::Module, ::Symbol) at ./loading.jl:853\n",
      " [9] include at ./boot.jl:326 [inlined]\n",
      " [10] include_relative(::Module, ::String) at ./loading.jl:1038\n",
      " [11] include(::Module, ::String) at ./sysimg.jl:29\n",
      " [12] top-level scope at none:2\n",
      " [13] eval at ./boot.jl:328 [inlined]\n",
      " [14] eval(::Expr) at ./client.jl:404\n",
      " [15] top-level scope at ./none:3\n",
      "during initialization of module SpecialFunctions\n",
      "in expression starting at /Users/ekin/.julia/dev/AutoGrad/src/AutoGrad.jl:55\n",
      "ERROR: LoadError: Failed to precompile AutoGrad [6710c13c-97f1-543f-91c5-74e8f7d95b35] to /Users/ekin/.julia/compiled/v1.1/AutoGrad/51RA4.ji.\n",
      "Stacktrace:\n",
      " [1] error(::String) at ./error.jl:33\n",
      " [2] compilecache(::Base.PkgId, ::String) at ./loading.jl:1197\n",
      " [3] _require(::Base.PkgId) at ./loading.jl:960\n",
      " [4] require(::Base.PkgId) at ./loading.jl:858\n",
      " [5] require(::Module, ::Symbol) at ./loading.jl:853\n",
      " [6] include at ./boot.jl:326 [inlined]\n",
      " [7] include_relative(::Module, ::String) at ./loading.jl:1038\n",
      " [8] include(::Module, ::String) at ./sysimg.jl:29\n",
      " [9] top-level scope at none:2\n",
      " [10] eval at ./boot.jl:328 [inlined]\n",
      " [11] eval(::Expr) at ./client.jl:404\n",
      " [12] top-level scope at ./none:3\n",
      "in expression starting at /Users/ekin/.julia/dev/Knet/src/Knet.jl:106\n"
     ]
    },
    {
     "ename": "ErrorException",
     "evalue": "Failed to precompile Knet [1902f260-5fb4-5aff-8c31-6271790ab950] to /Users/ekin/.julia/compiled/v1.1/Knet/f4vSz.ji.",
     "output_type": "error",
     "traceback": [
      "Failed to precompile Knet [1902f260-5fb4-5aff-8c31-6271790ab950] to /Users/ekin/.julia/compiled/v1.1/Knet/f4vSz.ji.",
      "",
      "Stacktrace:",
      " [1] error(::String) at ./error.jl:33",
      " [2] compilecache(::Base.PkgId, ::String) at ./loading.jl:1197",
      " [3] _require(::Base.PkgId) at ./loading.jl:960",
      " [4] require(::Base.PkgId) at ./loading.jl:858",
      " [5] require(::Module, ::Symbol) at ./loading.jl:853",
      " [6] top-level scope at In[28]:1"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "using Knet\n",
    "import Knet: Data\n",
    "include(Knet.dir(\"data\",\"mnist.jl\"))\n",
    "dtrn,dtst = mnistdata(xsize=(784,:)); # dtrn and dtst = [ (x1,y1), (x2,y2), ... ] where xi,yi are\n",
    "\n",
    "#Layers\n",
    "n = [784,128,64,10]\n",
    "N = length(n)-1\n",
    "init(sizes...) = 0.1randn(sizes...)\n",
    "\n",
    "#Nonlinearity\n",
    "h(x)    = x>0 ? x : zero(x) # relu\n",
    "h′(x,y) = y>0 ? one(x) : zero(x) # derivative of relu\n",
    "\n",
    "#Loss\n",
    "𝓁(x,a) = nll(x,a;average=true) # negative log likelihood loss, x is dxb matrix, \n",
    "                               # a is d-length integer array keeps the correct answers \n",
    "function 𝓁′(x,a)  # Note!: this will be simplified if we can figure out how to integrate derivative of getindex in to our formulatin\n",
    "    indices = Knet.findindices(x,a,dims=1)\n",
    "    yz = zero(x)\n",
    "    yz[indices] .= 1\n",
    "    return (softmax(x,dims=1) .- yz)./length(a)\n",
    "end\n",
    "\n",
    "#Forward Function\n",
    "function neural_net(params,input;h=h,h′= h′)\n",
    "    X     = [input]; δ     = []\n",
    "    for i=1:length(params)-1\n",
    "        x = params[i][1]*X[end] .+ params[i][2]         \n",
    "        push!(X,h.(x)); push!(δ,h′.(x,X[end]))\n",
    "    end \n",
    "    x = params[end][1]*X[end] .+ params[end][2]    \n",
    "    push!(X,x); push!(δ,one.(x))\n",
    "    X,δ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: dtrn not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: dtrn not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[27]:5",
      " [2] top-level scope at util.jl:156",
      " [3] top-level scope at In[27]:4"
     ]
    }
   ],
   "source": [
    "params =[[init(n[i+1],n[i]),zeros(n[i+1])] for i=1:N] # model parameters\n",
    "α = 0.5 # learning rate \n",
    "epochs=3# number of epochs to train model \n",
    "@time for i=1:epochs # 1 epoch takes ~ 65 seconds  in my macbook\n",
    "    for (x,y) in dtrn\n",
    "        X,δ = neural_net(params,x;h=h, h′= h′)\n",
    "        D = Diagonal([[HadMul(δ[i]) ∘ RightMul(X[i]) HadMul(δ[i])] for i=1:N])\n",
    "        ImL = Bidiagonal([I for i in 1:N], -[HadMul(δ[i]) ∘ LeftMul(params[i][1]) for i=2:N] , :L)\n",
    "        g = push!(Any[Zero() for i=1:N-1],𝓁′(X[N+1],y))\n",
    "        ∇J = D'*array.(ImL'\\g);\n",
    "        for i =1:length(params)\n",
    "            params[i][1] = params[i][1] - α*∇J[i][1]\n",
    "            params[i][2] = params[i][2] - α*sum(∇J[i][2],dims=2)\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroone=total=0\n",
    "for (x,y) in dtst\n",
    "    yn        = neural_net(params,x;h=h, h′= h′)[1][end]\n",
    "    answers   = vec(getindex.(argmax(yn,dims=1),1))\n",
    "    global zeroone += sum(y .== answers)\n",
    "    global total   += length(answers)\n",
    "end\n",
    "accuracy = 100zeroone/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network with Orthogonal Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "init (generic function with 1 method)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = [2,2,2,1]\n",
    "N = length(n)-1\n",
    "B = 7\n",
    "h(x) = exp(-x)\n",
    "h′(x,y) = -y\n",
    "𝓁(x,y) = sum(abs2,x-y)/2\n",
    "𝓁′(x,y) = x-y\n",
    "init(sizes...) = 0.01randn(sizes...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ort (generic function with 1 method)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct OrthogonalTransform{T} <: AbstractMatrix{T}\n",
    "    θ::T\n",
    "end\n",
    "Base.Matrix{T}(R::OrthogonalTransform{T}) where T =   [cos(R.θ) -sin(R.θ); sin(R.θ) cos(R.θ)] \n",
    "*(R::OrthogonalTransform, x::AbstractArray{T,2} where T) = [cos(R.θ) -sin(R.θ); sin(R.θ) cos(R.θ)]  * x\n",
    "Base.adjoint(R::OrthogonalTransform) = OrthogonalTransform(-R.θ)\n",
    "Base.size(R::OrthogonalTransform) = (2,2)\n",
    "Base.getindex(R::OrthogonalTransform, inds...) = [cos(R.θ) -sin(R.θ); sin(R.θ) cos(R.θ)][inds...]\n",
    "-(R::OrthogonalTransform{T}) where T = OrthogonalTransform{T}(-R.θ)\n",
    "Ort(Q::OrthogonalTransform) = LinearMatrixOp(X->Q*X, X->(X-Q*X'*Q)/2) # onl definition needed so far. So I left f as identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function neural_net(params,input;h=h,h′= h′)\n",
    "    X     = [input]\n",
    "    δ     = []\n",
    "    for i=1:length(params)\n",
    "        x = params[i][1]*X[i] .+ params[i][2]         \n",
    "        push!(X,h.(x))\n",
    "        push!(δ,h′.(x,X[i+1]))\n",
    "    end \n",
    "    X,δ\n",
    "end\n",
    "array(x)= fill(x,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2×2 OrthogonalTransform{Float64}:\n",
       " 0.707107  -0.707107\n",
       " 0.707107   0.707107"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OrthogonalTransform(π/rand([1,2,3,4,6])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params: `W_i` and `b_i`s: x_{i+1} <- Wi*x_i .+ b_i\n",
    "params =[[(i!=N ? OrthogonalTransform(π/rand([1,2,3,4,6])) : init(n[i+1],n[i])), init(n[i+1])] for i=1:N]\n",
    "x, y = init(n[1],B), init(1,B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Any,2},1}:\n",
       " [[-0.000178181 -6.77626e-21; 1.35525e-20 -0.000178181]; [0.00132289 0.00125169 … 0.00140132 0.00134872; -0.00482635 -0.00461089 … -0.00510602 -0.00491336]]\n",
       " [[-0.0151478 -0.0151478; 0.0151478 -0.0151478]; [-0.0043048 -0.00413347 … -0.00451705 -0.00438107; 0.00243219 0.00237051 … 0.00249019 0.00247303]]         \n",
       " [[-7.05508 -1.68532]; [-0.987071 -0.958283 … -1.0078 -1.00453]]                                                                                            "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,δ = neural_net(params,x)\n",
    "D = Diagonal([[HadMul(δ[i]) ∘ RightMul(X[i]) ∘  (i!=N ? Ort(params[i][1]) : IdentMul())     HadMul(δ[i])] for i=1:N])\n",
    "ImL = Bidiagonal([I for i in 1:N], -[HadMul(δ[i]) ∘ LeftMul(params[i][1]) for i=2:N] , :L)\n",
    "g = push!(Any[Zero() for i=1:N-1],𝓁′(X[N+1],y))\n",
    "∇J = D'*array.(ImL'\\g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Δ = sum(diff .* (∇J[1])[1]) = 3.563611434665406e-8\n",
      "Δ = updated - orig = 3.563559003438854e-8\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "diff = Matrix(OrthogonalTransform(params[1][1].θ + 𝜀)) - Matrix(params[1][1])\n",
    "@show Δ = sum(diff.* ∇J[1][1])\n",
    "orig    = 𝓁(neural_net(params,x)[1][N+1],y)\n",
    "params[1][1] = OrthogonalTransform(params[1][1].θ + 𝜀)\n",
    "updated = 𝓁(neural_net(params,x)[1][N+1],y)\n",
    "params[1][1] = OrthogonalTransform(params[1][1].θ - 𝜀)\n",
    "@show Δ = updated-orig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ort (generic function with 2 methods)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "struct HouseHolderTransform{T} <: AbstractMatrix{T}\n",
    "    mat::Matrix{T}\n",
    "end\n",
    "HouseHolderTransform(v::Vector{T}) where T = HouseHolderTransform(I-2*v*v')\n",
    "Base.Matrix{T}(R::HouseHolderTransform{T}) where T =   R.mat\n",
    "*(R::HouseHolderTransform, x::AbstractArray{T,2} where T) =  R.mat* x\n",
    "Base.adjoint(R::HouseHolderTransform) = HouseHolderTransform(permutedims(R.mat))\n",
    "Base.size(R::HouseHolderTransform) = size(R.mat)\n",
    "Base.getindex(R::HouseHolderTransform, inds...) = R.mat[inds...]\n",
    "-(R::HouseHolderTransform) = -R.mat\n",
    "Ort(Q::AbstractMatrix) = LinearMatrixOp(X->Q*X, X->(X-Q*X'*Q)/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = [4,4,4,1]\n",
    "N = length(n)-1\n",
    "B = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params: `W_i` and `b_i`s: x_{i+1} <- Wi*x_i .+ b_i\n",
    "vs = [init(n[i]) for i=1:N-1] # householder parameters\n",
    "vs = map(v-> (v ./ norm(v)), vs)\n",
    "params =[[(i!=N ? HouseHolderTransform(vs[i]) : init(n[i+1],n[i])), init(n[i+1])] for i=1:N]\n",
    "x, y = init(n[1],B), init(1,B);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Any,2},1}:\n",
       " [[-2.06631e-5 -1.56317e-6 -3.58314e-5 -6.15716e-5; 6.10719e-7 6.80924e-6 3.59571e-6 2.74547e-5; -1.61916e-5 1.08716e-5 -2.37478e-5 -2.05755e-6; -3.28906e-5 3.33844e-5 -4.448e-5 3.76017e-5]; [-0.00364452 -0.00362456 … -0.00356906 -0.00360129; 0.000655312 0.000630484 … 0.000633767 0.000627804; -0.00185489 -0.00184147 … -0.0018252 -0.00183877; -0.00291976 -0.00288985 … -0.00285274 -0.00289904]]\n",
       " [[-0.0138175 0.00587693 -0.00567307 -0.0107641; 0.00595036 0.0130423 0.00890904 0.0069044; -0.00198221 0.0111853 0.00348026 -3.75971e-5; -0.00503015 0.0104691 0.00139348 -0.002705]; [0.000836869 0.000829042 … 0.000814388 0.000834085; 0.00350536 0.0034517 … 0.00337857 0.00342527; 0.00267704 0.00264306 … 0.00263368 0.0026432; 0.00235646 0.00237045 … 0.00230256 0.00230227]]                     \n",
       " [[-1.80904 -4.15316 -2.81943 -2.42074]; [-0.991478 -0.984398 … -0.969487 -0.981775]]                                                                                                                                                                                                                                                                                                                      "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X,δ = neural_net(params,x)\n",
    "D = Diagonal([[HadMul(δ[i]) ∘ RightMul(X[i]) ∘  (i!=N ? Ort(params[i][1]) : IdentMul())     HadMul(δ[i])] for i=1:N])\n",
    "ImL = Bidiagonal([I for i in 1:N], -[HadMul(δ[i]) ∘ LeftMul(params[i][1]) for i=2:N] , :L)\n",
    "g = push!(Any[Zero() for i=1:N-1],𝓁′(X[N+1],y))\n",
    "∇J = D'*array.(ImL'\\g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×4 Array{Float64,2}:\n",
       " -2.06631e-5  -1.56317e-6  -3.58314e-5  -6.15716e-5\n",
       "  6.10719e-7   6.80924e-6   3.59571e-6   2.74547e-5\n",
       " -1.61916e-5   1.08716e-5  -2.37478e-5  -2.05755e-6\n",
       " -3.28906e-5   3.33844e-5  -4.448e-5     3.76017e-5"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "∇J[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Δ = sum(diff .* (∇J[1])[1]) = -4.686944645157155e-8\n",
      "Δ = updated - orig = -4.687085031207516e-8\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "vs1_changed = vs[1] .+ 𝜀\n",
    "vs1_changed = vs1_changed ./ norm(vs1_changed)\n",
    "#vs1_changed[1] = vs[1][1] + 𝜀\n",
    "diff = Matrix(HouseHolderTransform(vs1_changed)) - Matrix(params[1][1])\n",
    "@show Δ = sum(diff.* ∇J[1][1])\n",
    "orig    = 𝓁(neural_net(params,x)[1][N+1],y)\n",
    "params[1][1] = HouseHolderTransform(vs1_changed)\n",
    "updated = 𝓁(neural_net(params,x)[1][N+1],y)\n",
    "params[1][1] = HouseHolderTransform(vs[1])\n",
    "@show Δ = updated-orig;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " -0.7455803491491308\n",
       "  0.4113186460752907\n",
       " -0.4465610952799094\n",
       "  0.2747910161119856"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs1_changed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.1.0",
   "language": "julia",
   "name": "julia-1.1"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
